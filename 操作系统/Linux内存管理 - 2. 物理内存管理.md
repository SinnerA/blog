---
title: Linux内存管理 - 2. 物理内存管理
date: 2018-05-23
tags: Linux内核 内存管理
---

[TOC]

为了有效的管理物理内存（分配、回收），Linux将整个物理内存划分为若干个页，对每一个页，都有相关的数据结构来记录该页的状态和使用信息。在Linux中，每个页的大小是4KB。

对于每一个页，在Linux中都有一个struct page数据结构来记录该物理页的使用情况。所有页的struct page结构组成一个连续的数组存放在物理内存的某个地方。某页在物理内存中的物理地址除以4KB，就得到该页是第几个物理页索引，然后索引就可以查询struct page数组得到该页的具体信息。

![img](/Users/sinnera/sinnera.github.io/source/illustrations/linux_memory_10.png)

## 页帧分配与回收

### 分配

页是物理内存或虚拟内存中一组连续的线性地址，Linux内核以页为单位处理内存，页的大小 通常是4KB。当一个进程请求一定量的页面时，如果有可用的页面，内核会直接把这些页面分 配给这个进程，否则，内核会从其它进程或者页缓存中拿来一部分给这个进程用。内核知道 有多少页可用，也知道它们的位置。 

### 回收

如果在进程请求指定数量的内存页时没有可用的内存页，内核就会尝试释放特定的内存页 (以前使用过，现在没有使用，并且基于某些原则仍然被标记为活动状态)给新的请求使 用。这个过程叫做内存回收。**kswapd内核线程**和try_to_free_page()内核函数负责页面回收。 

kswapd通常在task interruptible状态下休眠，当一个区域中的空闲页低于阈值的时候，它就会被伙伴系统唤醒。它基于**最近最少使用原则(LRU，Least Recently Used)**在活动页中寻找可回收的页面。最近最少使用的页面被首先释放。它使用活动列表和非活动列表来维护候选页面。kswapd扫描活动列表，检查页面的近期使用情况，近期没有使用的页面被放入非活动列表中。使用vmstat -a命令可以查看有分别有多少内存被认为是活动和非活动状态

> 常见的页面置换算法：LRU，OPT（最佳置换），FIFO，CLOCK

kswapd还要遵循另外一个原则。页面主要有两种用途：页面缓存(page cahe)和进程地址空间 (process address space)。页面缓存是指映射到磁盘文件的页面；进程地址空间的页面(又叫做匿名内存，因为不是任何文件的映射，也没有名字)使用来做堆栈使用的。在回收内存时，**kswapd更偏向于回收页面缓存**。 

Page out和swap out：“page out”和“swap out”很容易混淆。“page out”意思是把一些页面 (整个地址空间的一部分)交换到swap；"swap out"意味着把所有的地址空间交换到 swap。 

如果大部分的页面缓存和进程地址空间来自于内存回收，在某些情况下，可能会影响性能。 我们可以通过/proc/sys/vm/swappiness文件来控制这个行为

## 伙伴算法（buddy）

伙伴分配的实质就是一种特殊的**“分离适配”**，即将内存按2的幂进行划分，相当于分离出若干个块大小一致的空闲链表，搜索该链表并给出同需求最佳匹配的大小。

其优点是快速搜索合并（O(logN)时间复杂度）以及低外部碎片（最佳适配best-fit）；

其缺点是内部碎片，因为按2的幂划分块，如果碰上66单位大小，那么必须划分128单位大小的块。但若需求本身就按2的幂分配，比如可以先分配若干个内存池，在其基础上进一步细分就很有吸引力了。

在每个内存管理区中都有一个free_area数组，该数组的长度为MAX_ORDER，默认值为11。free_area数组描述的就是伙伴算法中每个分配阶（从0到11）所对应的页框块链表。

![img](/Users/sinnera/sinnera.github.io/source/illustrations/buddy_01.png)

注：上面每条链都是双向链表。

### 过程

#### 分配内存

寻找大小合适的内存块（大于等于所需大小并且最接近2的幂，比如需要27，实际分配32）

- 如果找到了，分配给应用程序
- 如果没找到，分出合适的内存块
  1. 对半分离出高于所需大小的空闲内存块
  2. 如果分到最低限度，分配这个大小。
  3. 回溯到步骤1（寻找合适大小的块）
  4. 重复该步骤直到一个合适的块

#### 释放内存

释放该内存块

- 寻找相邻的块，看其是否释放了。
- 如果相邻块也释放了，合并这两个块，重复上述步骤直到遇上未释放的相邻块，或者达到最高上限（即所有内存都释放了）。

#### 举例

看个内存分配和释放的示意图：

![img](https://coolshell.cn/wp-content/uploads/2013/10/buddy-memory-allocation.jpg)

上图中，首先我们假设我们一个内存块有1024K，当我们需要给A分配70K内存的时候，

1. 我们发现1024K的一半大于70K，然后我们就把1024K的内存分成两半，一半512K。
2. 然后我们发现512K的一半仍然大于70K，于是我们再把512K的内存再分成两半，一半是128K。
3. 此时，我们发现128K的一半小于70K，于是我们就分配为A分配128K的内存。

后面的，B，C，D都这样，而释放内存时，则会把相邻的块一步一步地合并起来（合并也必需按分裂的逆操作进行合并）。

### 实现

我们除了需要一个free_list来表示所有free page之外，通常还使用完全二叉树来记录page的使用状态。

分配器的整体思想是，通过一个**数组形式的完全二叉树**来监控管理内存，二叉树的节点用于标记相应内存块的使用状态，高层节点对应大的块，低层节点对应小的块，在分配和释放中我们就通过这些节点的标记属性来进行块的分离合并。如图所示，假设总大小为16单位的内存，我们就建立一个深度为5的满二叉树，根节点从数组下标[0]开始，监控大小16的块；它的左右孩子节点下标[1~2]，监控大小8的块；第三层节点下标[3~6]监控大小4的块……依此类推。

![img](/Users/sinnera/sinnera.github.io/source/illustrations/buddy_02.png)

在分配阶段，首先要搜索大小适配的块，假设第一次分配3，转换成2的幂是4，我们先要对整个内存进行对半切割，从16切割到4需要两步，那么从下标[0]节点开始深度搜索到下标[3]的节点并将其标记为已分配。第二次再分配3那么就标记下标[4]的节点。第三次分配6，即大小为8，那么搜索下标[2]的节点，因为下标[1]所对应的块被下标[3~4]占用了。

在释放阶段，我们依次释放上述第一次和第二次分配的块，即先释放[3]再释放[4]，当释放下标[4]节点后，我们发现之前释放的[3]是相邻的，于是我们立马将这两个节点进行合并，这样一来下次分配大小8的时候，我们就可以搜索到下标[1]适配了。若进一步释放下标[2]，同[1]合并后整个内存就回归到初始状态。

### 总结

1. free_list数组记录了所有的2的幂大小的空闲页面，大小相同的页面用双向链表串起来
2. 分配时，对空闲页面进行对半分裂，直到找到best-fit的页面
3. 释放时，合并相邻空闲页面
4. 采用完全二叉树记录页面分配情况
5. 优点是快速搜索合并（O(logN)时间复杂度）以及低外部碎片（最佳适配best-fit）；其缺点是内部碎片

注：`jemalloc`是一种现代的内存分配器，其中采用了伙伴技术。

## slab分配器

伙伴系统会产生内部碎片，因此为了**解决小块内存的分配**，Linux内核基于Solaris 2.4中的slab分配算法实现了自己的slab分配器。除此之外，slab分配器另一个主要功能是作为一个**高速缓存**，它用来存储内核中那些经常分配并释放的对象。

### 基本原理

slab分配器中用到了**对象**这个概念，所谓对象就是内核中的数据结构以及对该数据结构进行创建和撤销的操作。它的基本思想是将内核中经常使用的对象放到高速缓存中，并且由系统保持为初始的可利用状态。

比如进程描述符（task_struct），内核中会频繁对此数据进行申请和释放。当一个新进程创建时，内核会直接从slab分配器的高速缓存中获取一个已经初始化了的对象；当进程结束时，该结构所占的页框并不被释放，而是重新返回slab分配器中。

如果没有基于对象的slab分配器，内核将花费更多的时间去分配、初始化以及释放一个对象。

slab分配器有以下三个基本目标：

1. 减少伙伴算法在分配小块连续内存时所产生的**内部碎片**
2. 将**频繁使用的对象缓存**起来，减少分配、初始化和释放对象的时间开销
3. 通过着色技术调整对象，将对象与L1或L2高速缓存对齐，以更好的使用**硬件高速缓存**

### 结构

slab分配器为每种对象分配一个高速缓存，这个缓存可以看做是**同类型对象**的一种储备。

每个高速缓存所占的内存区又被划分多个slab，每个slab是由一个或多个**连续的页框**组成。

每个**页框中包含若干个对象**，既有已经分配的对象，也包含空闲的对象。

同种类型的cache下，有3种slabs：slabs_full，slabs_partial，slabs_full。

slab分配器的大致组成图如下：

![img](/Users/sinnera/sinnera.github.io/source/illustrations/slab_struct.png)

### 策略

#### 内部碎片

为了减少由伙伴系统产生的内部碎片，slab提供了2个caches集合（free_list），大小范围从2^5(32) B到2^17 (131072)B，其中一个是给DMA用的，剩下那个是给NORMAl区使用的。并且提供了kmalloc函数用于分配这些cache，相应的有kfree，注意kmalloc是为内核空间NORMAL区申请内存。

#### 维护常用对象的缓存

相同类型的对象归为一类，每当要申请这样一个对象时，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免内部碎片。

slab分配器并不丢弃已经分配的对象，而是释放并把它们保存在内存中，只是更新为可用标记。slab分配对象时，会使用最近释放的对象的内存块，因此其驻留在cpu高速缓存中的概率会大大提高。

#### 硬件高速缓存

 CPU cache 的工作原理：

CPU cache 就是我们常看到的一级缓存，二级缓存，三级缓存啊，引入这些缓存是因为内存 RAM 的速度相较于 CPU 的速度而言，是在是太慢了，所以为了提高速度， CPU 制造商提供了速度接近于 CPU 的小容量缓存，以便加速 CPU 与 RAM 的数据交换。

具体的策略是：

**每块 cache 会被分为更小的cache line**，每个 cache line 的容量是一样的

然后 **CPU 将虚拟地址分成三部分—— data, index, tag**，其中 data 长度是 cache line 的长度，index 的长度是 cache 的长度减去 data 的长度，最后 tag 的长度是虚拟地址的长度减去 data+index 的长度。举个例子，在 x86 的机器中，虚拟地址的地址空间是 32bit=2^32 ，假设我们的一级缓存有 4MB=2^22，cache line 的长度是 64bit=2^6 ，所以，data就是 6 位，index 就是 (22-6) = 12 位，tag 就是 32-22=10 位。

然后得到这些位之后，CPU 的每一个虚拟地址，将其分成上面的三部分之后，将**按照 index 作为索引存入到 cache中**，然后在看需要的内容是否在cache中，这回比较需要的虚拟地址的tag与cache对应索引index的tag是否一致，如果一致说明cache hit ，否则说明cache miss 。

针对CPU cache的原理，slab利用剩余的不足一个 object 的空间来进行缓存染色。具体说来，就是以平台的 cache line 的长度（存储在 cachep->colour_off）为偏移值（**这一点非常重要！**），计算出剩余的空间有多少个偏移值 cachep->colour ，然后就从 0 到 cachep->colour - 1（这个值是 l3->colour_next），每次就偏移 colour_next * colour_off 。

这样，根据我们上面的叙述，**每个slab将最终被放到不同的 cache line，从而缓解了缓存过热的问题**

### 高速缓存

#### 通用高速缓存

slab分配器所提供的小块连续内存的分配是通过**通用高速缓存**实现的。通用高速缓存所提供的对象具有几何分布的大小，范围为32到131072字节。内核中提供了kmalloc()和kfree()两个接口分别进行内存的申请和释放。

#### 专用高速缓存

内核为**专用高速缓存**的申请和释放提供了一套完整的接口，根据所传入的参数为**具体的对象**分配slab缓存。kmem_cache_create()用于对一个指定的对象创建高速缓存。kmem_cache_alloc()在其参数所指定的高速缓存中分配一个slab。相反，kmem_cache_free()在其参数所指定的高速缓存中释放一个slab。

### 过程

1. 初始化：

   1. 初始化kmem_cache，就是缓存队列
   2. 建立kmalloc需要的array_cache，即大小范围从2^5(32) B到2^17 (131072)B的free_list，完成这一步就相当于 kmalloc() 完全可用了
   3. 将对象大小与硬件高速缓存对齐
   4. 后续还有些细节...

2. 分配内存：

   初始化slab之后，并没有分配真正的内存空间，而是按需分配。如果cache不足，则从伙伴系统申请内存建立新的slab。

3. 回收内存：放回slabs_free中，并将该对象标记为空闲并可用

4. 销毁内存：缓存不会自动销毁，当**kswapd**发现内存紧张时，它会调用 `kmem_cache_reap（）`释放一些内存

#### 举例

如果有一个名叫inode_cachep的kmem_cache节点，它存放了一些inode对象。当内核请求分配一个新的inode对象时，slab分配器就开始工作了：

- 首先要查看inode_cachep的slabs_partial链表，如果slabs_partial非空，就从中选中一个slab，返回一个指向已分配但未使用的inode结构的指针。完事之后，如果这个slab满了，就把它从slabs_partial中删除，插入到slabs_full中去，结束；
- 如果slabs_partial为空，也就是没有半满的slab，就会到slabs_empty中寻找。如果slabs_empty非空，就选中一个slab，返回一个指向已分配但未使用的inode结构的指针，然后将这个slab从slabs_empty中删除，插入到slabs_partial（或者slab_full）中去，结束；
- 如果slabs_empty也为空，那没办法，cache内存已经不足，只能从伙伴系统中引入新的页来建立新的slab了

### 总结

1. 3大任务：减少内部碎片，缓存对象，CPU缓存加速
2. free_list维护固定规格的小对象列表，提供kmalloc和kfree（通用缓存）
3. 不同的对象对应不同的cache，cache维护了3种类型的slab，里面维护了空闲对象，用于分配（专用缓存）
4. 对齐cache line，提高CPU cache的命中率
5. 一般不主动将缓存回收，当kswapd时发现内存吃紧时再回收

## vmalloc

vmalloc是一个接口函数, 内核代码使用它来分配在虚拟内存中连续但在物理内存中不一定连续的内存

使用vmalloc的最著名的实例是内核对模块的实现. 因为模块可能在任何时候加载, 如果模块数据比较多, 那么无法保证有足够的连续内存可用, 特别是在系统已经运行了比较长时间的情况下。

因为用于vmalloc的内存页总是必须映射在内核地址空间中, 因此使用`ZONE_HIGHMEM`内存域的页要优于其他内存域. 这使得内核可以节省更宝贵的较低端内存域, 而又不会带来额外的坏处. 因此, `vmalloc`等映射函数是内核出于自身的目的(并非因为用户空间应用程序)使用高端内存页的少数情形之一。

### 数据结构

vmalloc区也被称为非连续内存区域，它由若干个vmalloc区组成，每个vmalloc区之间间隔4KB，这是为了防止非法的内存访问。内核中使用vm_struct结构来表示每个vmalloc区，也就是说，每次调用vmalloc()函数在内核中申请一段连续的内存后，都对应着一个vm_struct，系统中所有的vmalloc区组成一个链表，链表头指针为vmlist。

> 注意, 内核使用了一个重要的数据结构称之为`vm_area_struct`, 以管理用户空间进程的虚拟地址空间内容. 尽管名称和目的都是类似的, 虽然二者都是做虚拟地址空间映射的, 但不能混淆这两个结构。
>
> 1. 前者是内核虚拟地址空间映射，而后者则是应用进程虚拟地址空间映射。
> 2. 前者不会产生page fault，而后者一般不会提前分配页面，只有当访问的时候，产生page fault来分配页面。

### 实现

- 首先, `get_vm_area`在`vmalloc`地址空间中找到一个适当的区域.
- 接下来从物理内存分配各个页
- 最后将这些页连续地映射到`vmalloc`区域中, 分配虚拟内存的工作就完成了

## 页面回收

### 回收原理

用户进程内存空间中数据有两种:

1. 从文件系统中读进来的数据 (主要有文件内容高速缓存, 程序代码和共享库)
2. 程序使用的堆栈空间

而Linux是一个分页请求系统, 用户进程使用的所有内存需要映射到物理内存：

1. 应用程序的地址空间是虚拟空间, 是按被分成固定大小的页 (page) 来管理的
2. 物理内存也是按固定大小的页框 (page frames) 来组织
3. 虚拟页面 (page) 需要由操作系统映射到物理内存中的页框 (page frames)

为了更好的利用物理内存，Linux 会对在物理内存中的页面进行回收：

- 如果存放的是程序代码或共享库, 可以直接回收 (以后需要的时候可以从文件里面直接读入)
- 如果缓存的是文件内容, 如果是脏页, 先写回磁盘后再回收; 如果不是脏页可以直接回收
- 而对于程序使用的堆栈空间，由于没有对应的文件 (叫做 "匿名页", anonymous pages), 只能是备份到磁盘上一块专门的分区, 这个专门的分区就是Swap Space.
- 一旦回收算法既不能从文件缓存回收内存，又不能从正在使用的匿名页中回收内存，而系统需要满足更多的内存请求，这个时候只能用最后一招了: OOM kill

### working set

进程的working set是指当前在物理内存中，属于该进程的pages组成的集合。

这个集合中的page数随着系统的运行，可能扩大也可能缩小。扩大working set是指进程正在访问更多的内存时。  缩小working set是指其他进程正在访问更多的内存，并且整个物理内存的空间不足，需要将某些干净的内存页free掉或者一些脏的内存页swap到交换分区去，如果这个操作设计到当前进程，对当前进程来说就是shrink working set。

缩小working set需要遵循lru (内核的内存老化)算法，并不是随便挑选PAGE进行shrink的。

### swap

swap和前面提到的shrink working set有关，如果是干净页（即从读入虚拟地址空间后，没有修改过的页），则直接标记为free，不需要写盘，也不会发生swap。  如果是脏页，那么它需要写盘，或者需要swap 到交换分区。

#### swap space

swap space是**磁盘**上的一块区域，可以是一个分区，也可以是一个文件，或者是他们的组合。简单点说，当系统物理内存吃紧时，Linux会将内存中**不常访问的数据保存到swap上**，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问swap上存储的内容时，再将swap上的数据加载到内存中，这就是我们常说的swap out和swap in。

像getty这类守护进程随着开机启动，可是却很少使用到，此时，让它腾出宝贵的物理内存， 把内存页移动到swap似乎是很有益的，Linux正是这么做的。所以，即使swap空间使用率到了50%也没必要惊慌。因为swap空间不是用来说明内存出现瓶颈，而是体现了Linux的高效性。

磁盘的速度和内存比较起来慢了好几个数量级，如果不停的读写swap，那么对系统的性能肯定有影响，尤其是当系统内存很吃紧的时候，读写swap空间发生的频率会很高，导致系统运行很慢。

从swap space的原理得出以下结论:

- Swap Space不会拖慢系统. 事实上, 不分配 swap space 并不代表就没有换进换出发生 (非匿名页还是可能会被换进换出).有了 Swap Space, 只是说在试图回收内存时, Linux 有了更多的选择
- Swap Space只是匿名页专用的. 在任何情况下, 程序代码, 共享库, 文件系统cache不会使用 Swap Space
- 由上面的 1, 2 两点可以知道: "尽量给 Swap Space 分配很小的空间" 唯一的好处就是不浪费磁盘空间 (也就是说最小化 Swap Space 大小并不能提升系统性能)
- 系统监控时, 要特别注意是否发生了OOM的情况, 一旦 OOM 发生, Linux 会自己挑选一个消耗内存较大, 又不 "重要" 的程序 kill 掉来回收内存 (但很多时候被kill掉的正好是某个应用程序)

#### 优化swap

建议使用IOPS和读写带宽很高的盘作为SWAP分区，例如PCI-E SSD。

实际上，我们更关注的应该是swap分区的大小问题。 设置多大才是最优的。下面是ubuntu给出的建议：

- 当物理内存小于1G且不需要休眠时，设置和内存同样大小的swap空间即可；当需要休眠时，建议配置两倍物理内存的大小，但最大值不要超过两倍内存大小
- 当物理内存大于1G且不需要休眠时，建议大小为round(sqrt(RAM))，其中RAM为物理内存大小；当需要休眠时，建议大小是RAM+round(sqrt(RAM))，但最大值不要超过两倍内存大小
- 如果两倍物理内存大小的swap空间还不够用，建议增加内存而不是增加swap

### OOM

前面讲到了shrink working set，是指系统在内存调度时，使用的一种手段，尽可能的让系统能使用有限的内存资源，支撑更多的并发任务。

oom是指系统已经没有足够的内存给进程使用，即能free的都已经free了，能swap out的也已经swap out了，再也不能挤出物理内存的情况。如果遇到这种情况就会发生OOM，表示系统内存以及不足，Linux会挑选并kill一些进程，来释放内存。

## Caches

为了提高系统性能，Linux使用了一些跟内存管理相关的cache，并且尽量将空闲的内存用于这些cache。这些cache都是系统全局共享的：

- Buffer Cache
  用来缓冲块设备上的数据，比如磁盘，当读写块设备时，系统会将相应的数据存放到这个cache中，等下次再访问时，可以直接从cache中拿数据，从而提高系统效率。它里面的数据结构是一个块设备ID和block编号到具体数据的映射，只要根据块设备ID和块的编号，就能找到相应的数据。
- Page Cache
  这个cache主要用来加快读写磁盘上文件的速度。它里面的数据结构是文件ID和offset到文件内容的映射，根据文件ID和offset就能找到相应的数据（这里文件ID可能是inode或者path，本人没有仔细去研究）。

从上面的定义可以看出，page cache和buffer cache有重叠的地方，不过实际情况是buffer cache只缓存page cache不缓存的那部分内容，比如磁盘上文件的元数据。所以一般情况下和page cache相比，Buffer Cache的大小基本可以忽略不计。

当然，使用cache也有一些不好的地方，比如需要时间和空间去维护cache，cache一旦出错，整个系统就挂了。

## VM管理器架构图

![img](/Users/sinnera/sinnera.github.io/source/illustrations/vm_manager.png)

1. Linux kernel 主要提供了两种内存分配算法: buddy 和 slab, 结合使用。buddy 提供了2的幂大小内存块的分配方法，具有数组特性，简单高效, 但是缺点在于内存碎片。slab 提供了小对象的内存分配方法, 实际上是一个多级缓存列表, 最小的分配单位称为一个slab(一个或者多个连续页), 被分配为多个对象来使用.
2. **kswapd**是一个内核线程，对系统内存做定时检查, 一般是1秒一次. 如果发现没有足够的空闲页面, 就做页回收(page reclaiming), 将不再使用的页面换出。如果要换出的页面脏了, 往往还需要写回到磁盘或者swap.
3. **bdflush**也是内核线程，周期性的检查脏缓冲(磁盘cache)，并写回磁盘。不过在 Linux 2.6 之后, pdflush 取代了 bdflush, 前者的优势在于：可以开多个线程, 而 bdflush 只能是单线程, 这就保证了不会在回写繁忙时阻塞; 另外, bdflush 的操作对象是缓冲, 而 pdflush 是基于页面的, 显然 pdflush 的效率会更高.

## 注意

1. 伙伴系统是Linux用于分配物理内存的，无论内核空间还是用户空间，要分配物理内存都是经过伙伴系统
2. slab的存在，是为了内核空间申请物理内存更加高效，而用户空间的可以自己实现相关优化，比如glibc使用的是ptmalloc

## 参考

[伙伴分配器的一个极简实现](https://coolshell.cn/articles/10427.html)

[Chapter 8  Slab Allocator](https://www.kernel.org/doc/gorman/html/understand/understand011.html)

[Linux内存管理中的slab分配器](http://edsionte.com/techblog/archives/4019)

[SLAB 分配器和 kmalloc](http://kernel.meizu.com/slab-allocator-and-kmalloc.html)

[Linux 之 VM](http://www.gaccob.com/publish/2014-06-15-linux-vm.html)

[page fault带来的性能问题](https://yq.aliyun.com/articles/55820)